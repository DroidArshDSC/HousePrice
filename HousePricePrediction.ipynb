{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653c08b9-8f17-4d2a-b171-69596526b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dd0b3f7-c9f3-471e-b0f6-86c273734544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GdPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0        1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1        2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2        3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3        4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4        5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1455  1456          60       RL         62.0     7917   Pave   NaN      Reg   \n",
       "1456  1457          20       RL         85.0    13175   Pave   NaN      Reg   \n",
       "1457  1458          70       RL         66.0     9042   Pave   NaN      Reg   \n",
       "1458  1459          20       RL         68.0     9717   Pave   NaN      Reg   \n",
       "1459  1460          20       RL         75.0     9937   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... PoolArea PoolQC  Fence MiscFeature MiscVal  \\\n",
       "0            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "2            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "3            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "4            Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "...          ...       ...  ...      ...    ...    ...         ...     ...   \n",
       "1455         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1456         Lvl    AllPub  ...        0    NaN  MnPrv         NaN       0   \n",
       "1457         Lvl    AllPub  ...        0    NaN  GdPrv        Shed    2500   \n",
       "1458         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "1459         Lvl    AllPub  ...        0    NaN    NaN         NaN       0   \n",
       "\n",
       "     MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0         2   2008        WD         Normal     208500  \n",
       "1         5   2007        WD         Normal     181500  \n",
       "2         9   2008        WD         Normal     223500  \n",
       "3         2   2006        WD        Abnorml     140000  \n",
       "4        12   2008        WD         Normal     250000  \n",
       "...     ...    ...       ...            ...        ...  \n",
       "1455      8   2007        WD         Normal     175000  \n",
       "1456      2   2010        WD         Normal     210000  \n",
       "1457      5   2010        WD         Normal     266500  \n",
       "1458      4   2010        WD         Normal     142125  \n",
       "1459      6   2008        WD         Normal     147500  \n",
       "\n",
       "[1460 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df=pd.read_csv('train.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38688938-fd87-407a-8342-d36d36109ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1936</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>160</td>\n",
       "      <td>RM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1894</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>160.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>85</td>\n",
       "      <td>RL</td>\n",
       "      <td>62.0</td>\n",
       "      <td>10441</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>Shed</td>\n",
       "      <td>700</td>\n",
       "      <td>7</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>9627</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0     1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1     1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2     1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3     1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4     1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "...    ...         ...      ...          ...      ...    ...   ...      ...   \n",
       "1454  2915         160       RM         21.0     1936   Pave   NaN      Reg   \n",
       "1455  2916         160       RM         21.0     1894   Pave   NaN      Reg   \n",
       "1456  2917          20       RL        160.0    20000   Pave   NaN      Reg   \n",
       "1457  2918          85       RL         62.0    10441   Pave   NaN      Reg   \n",
       "1458  2919          60       RL         74.0     9627   Pave   NaN      Reg   \n",
       "\n",
       "     LandContour Utilities  ... ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0            Lvl    AllPub  ...         120        0    NaN  MnPrv   \n",
       "1            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "2            Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "3            Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "4            HLS    AllPub  ...         144        0    NaN    NaN   \n",
       "...          ...       ...  ...         ...      ...    ...    ...   \n",
       "1454         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1455         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1456         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "1457         Lvl    AllPub  ...           0        0    NaN  MnPrv   \n",
       "1458         Lvl    AllPub  ...           0        0    NaN    NaN   \n",
       "\n",
       "     MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0            NaN       0      6    2010        WD         Normal  \n",
       "1           Gar2   12500      6    2010        WD         Normal  \n",
       "2            NaN       0      3    2010        WD         Normal  \n",
       "3            NaN       0      6    2010        WD         Normal  \n",
       "4            NaN       0      1    2010        WD         Normal  \n",
       "...          ...     ...    ...     ...       ...            ...  \n",
       "1454         NaN       0      6    2006        WD         Normal  \n",
       "1455         NaN       0      4    2006        WD        Abnorml  \n",
       "1456         NaN       0      9    2006        WD        Abnorml  \n",
       "1457        Shed     700      7    2006        WD         Normal  \n",
       "1458         NaN       0     11    2006        WD         Normal  \n",
       "\n",
       "[1459 rows x 80 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('test.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfc03bf5-9f5a-4449-bae9-83711073ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3788b798-53c7-4aa2-a87c-9146cbec4b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df=train_df.drop(['Id','SalePrice','PoolQC'],axis=1)\n",
    "input_cols=list(price_df.columns)[1:-1]\n",
    "target_cols=list(train_df.columns)[-1]\n",
    "inputs_df=price_df[input_cols].copy()\n",
    "target_df=train_df[target_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acf1114c-9bd9-4795-813b-8cf9be0a93aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols=inputs_df.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "categorical_cols=inputs_df.select_dtypes(include=['object']).columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "754a7418-f8d0-4e0e-9985-d8ee2447e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_count=inputs_df[numeric_cols].isna().sum().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa7928c9-11dc-4466-912d-e39bfaa86fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=SimpleImputer(strategy = 'mean').fit(price_df[numeric_cols])\n",
    "inputs_df[numeric_cols]=imputer.transform(inputs_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1c99795-a12b-4856-9e08-fbb2451cde0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2006.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>313.0</td>\n",
       "      <td>215245.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>5644.0</td>\n",
       "      <td>1474.0</td>\n",
       "      <td>2336.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>508.0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>738.0</td>\n",
       "      <td>15500.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "min         21.0    1300.0          1.0          1.0     1872.0        1950.0   \n",
       "max        313.0  215245.0         10.0          9.0     2010.0        2010.0   \n",
       "\n",
       "     MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  GarageArea  \\\n",
       "min         0.0         0.0         0.0        0.0  ...         0.0   \n",
       "max      1600.0      5644.0      1474.0     2336.0  ...      1418.0   \n",
       "\n",
       "     WoodDeckSF  OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  \\\n",
       "min         0.0          0.0            0.0        0.0          0.0       0.0   \n",
       "max       857.0        547.0          552.0      508.0        480.0     738.0   \n",
       "\n",
       "     MiscVal  MoSold  YrSold  \n",
       "min      0.0     1.0  2006.0  \n",
       "max  15500.0    12.0  2010.0  \n",
       "\n",
       "[2 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_df[numeric_cols].describe().loc[['min','max']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3b34eac-85d0-4f81-89b4-ce9ed17c2bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(price_df[numeric_cols])\n",
    "inputs_df[numeric_cols]=scaler.transform(inputs_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8707a3f-5911-4679-a5d4-da2bbf2267cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
      "C:\\Users\\Arsh Chadha\\AppData\\Local\\Temp\\ipykernel_1604\\2143375519.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder=OneHotEncoder(sparse_output=False,handle_unknown='error')\n",
    "encoder.fit(price_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15cd4925-3a9e-4343-83d6-839929b8f890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75fe434d-8424-4aa3-aa17-37abed7a36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs,val_inputs,train_targets,val_targets=train_test_split(inputs_df[numeric_cols+encoded_cols],target_df,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c1aaeca4-846b-4dd9-82af-49f5c38e3c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 1095 entries, 1023 to 1126\n",
      "Series name: SalePrice\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "1095 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 17.1 KB\n"
     ]
    }
   ],
   "source": [
    "train_targets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33fa25e1-7f25-414f-92fb-4f46046e725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91bb1779-b3ca-4da6-b413-360136684972",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Ridge()\n",
    "model.fit(train_inputs,train_targets)\n",
    "y_pred=model.predict(train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "409b3df4-02c1-4cfd-823d-21bdf1b73703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([158710.21163489, 348528.76879195,  89119.36876176, 189671.55717484,\n",
       "       344818.92083818,  61320.35376958, 248739.81551567, 148540.47692691,\n",
       "        57536.83786641, 143117.62439371, 146071.86528264, 105106.80285037,\n",
       "        92631.99686358, 225480.96940922, 176973.43128281, 133338.6785094 ,\n",
       "       186985.15544259, 128020.92081614, 129044.82947022, 211238.10894139,\n",
       "       161509.55240934, 203363.50350123, 181042.78342316, 130380.89826811,\n",
       "       203040.16498801, 141979.80660257, 201554.88462324, 101578.76643942,\n",
       "       171424.34572079, 211239.64312512, 137819.05923705, 274058.98309531,\n",
       "       242910.91983738, 107372.69994492, 249192.63035507, 144616.34006543,\n",
       "       129706.30488355, 203545.37694798, 321827.45797285, 111061.8579651 ,\n",
       "       137655.45607624, 227284.04807935,  97580.24038286, 355648.90742741,\n",
       "       135816.97232581, 144892.53643372, 106031.52139559, 137664.48871553,\n",
       "       416308.53951218, 130320.18993579, 118743.25422824, 262332.27743735,\n",
       "        96926.19516336, 264996.95070882, 168372.15847136, 226920.66906215,\n",
       "       209673.29561905, 183673.65012254, 137690.99999413,  98106.58305059,\n",
       "        41888.11424706, 171803.00650736, 317661.34382914, 256809.48313088,\n",
       "       315413.00060538, 194063.75422529,  90743.66555681, 296827.22242669,\n",
       "       118980.16192785, 174635.46576837, 106318.61035329, 116740.5926018 ,\n",
       "       107454.38243564,  57394.36648996, 440496.7088567 , 197760.2073766 ,\n",
       "       301646.15885003, 379039.69183538, 148895.50203391, 118036.44463479,\n",
       "       112037.76807025,  47410.25543293, 113483.82478544,  88713.74586954,\n",
       "       162493.68946984, 140012.94932201, 253162.87572539, 223634.56132409,\n",
       "       131820.66059622, 198077.92617922, 139062.96188597, 154922.66007105,\n",
       "       177257.98303796, 271180.9248911 , 118563.65069401, 192843.75808439,\n",
       "       206794.70248803, 169469.482496  , 203796.17430488, 272041.36972947,\n",
       "       141072.20888625, 208243.2231682 , 265508.60197728, 146407.5954045 ,\n",
       "       190379.17374138, 193993.13583807, 147635.99529598, 307655.85134193,\n",
       "       157237.36634352, 219458.69110519,  65228.1958682 , 145109.64853829,\n",
       "       148045.45178085, 135170.91871159, 202094.49446589, 137181.96542342,\n",
       "        96195.42028628, 121355.24330338, 114322.89948261, 273333.4930152 ,\n",
       "        91099.91358869, 134052.63694709, 184420.51388536, 182577.29085307,\n",
       "       194703.46888803, 132239.48557945, 231792.05460811,  92477.64113769,\n",
       "       145402.62894385, 194488.53756916, 187337.6334296 , 330061.19971079,\n",
       "       193595.17781646, 139922.25596618,  40207.60374769, 382338.67026852,\n",
       "       343834.49944673, 148534.22008888, 227566.10251849, 557781.90910565,\n",
       "       347629.91413266, 132389.84979308, 182003.34663172, 161678.54509863,\n",
       "       122627.14309283, 106918.63835844, 239123.02388183, 191324.31564188,\n",
       "       122993.35757622,  50175.28031564, 133658.18005734, 126334.35495353,\n",
       "       253843.40879032, 159513.91594179,  71667.73113658, 115544.12788256,\n",
       "       100014.02143106, 154953.67037163,  95171.70788509, 133570.15194774,\n",
       "       219871.35491877,  86957.53302665, 291316.86664616, 158220.93445713,\n",
       "       114966.32904039, 134877.47433264, 263137.99027263, 334472.92758154,\n",
       "       432367.9063699 , 221911.66776604, 384891.71389838,  95148.93763144,\n",
       "       122412.0964333 , 144828.43490324, 309846.38040666, 105223.93257578,\n",
       "       121178.51827739, 217358.13660588, 133888.10081537, 159260.20888516,\n",
       "       205818.88878052,  95747.67420117, 124499.99239664, 151468.26082779,\n",
       "       232308.53270191, 104765.12503913, 254721.87008557, 216165.81272671,\n",
       "       200487.48113877,  71342.72622951, 116401.82294895, 100118.37570058,\n",
       "       161808.62879351, 152970.63879347, 196643.78371199, 201302.67276809,\n",
       "       192186.7449628 ,  90980.16374998, 208636.74953502, 136978.80063137,\n",
       "       267497.33497643, 225021.82825465, 108558.46778939, 306149.89916028,\n",
       "       196710.77318302, 114814.07202666, 226761.75794288, 135773.60236364,\n",
       "       134249.28164522, 101582.5899928 , 218340.71236253, 154683.16838317,\n",
       "       117527.43689123, 171877.61721662, 204318.13569426, 245143.43831085,\n",
       "       212633.90274542, 131825.91523225, 157028.32980772, 114325.56824681,\n",
       "       134358.81076869, 213811.03622392, 196573.25228315,  90660.05523345,\n",
       "       231490.63218646, 137163.11927833,  76517.04168392,  93347.32453628,\n",
       "       158340.91971047, 107965.52865178, 101146.70178057, 167493.08811281,\n",
       "       115002.25707867, 115609.43091492, 236095.20985084, 140638.46445029,\n",
       "       203608.58820064, 158988.59957385, 245379.21145572, 110332.22180261,\n",
       "       108877.55050108, 255441.23867669, 224965.61348876, 469995.96128804,\n",
       "       197130.06683807, 131369.39732561, 121778.87827692, 169147.93591482,\n",
       "       144925.50163447,  91948.75642854, 169612.02705488, 165533.04596015,\n",
       "       151345.20080743, 116057.95520136, 139112.43397653, 133228.11636278,\n",
       "       101405.88989774, 129527.84899636, 181327.01085317, 237060.58884891,\n",
       "       287714.06323231, 190629.64421023, 136224.31527937, 236698.29020961,\n",
       "       348054.04386102, 230372.39280479, 161932.49878247, 131744.71673638,\n",
       "       110077.35784338, 190258.72039746, 399970.79031394, 237116.46302446,\n",
       "       228173.87680052,  74752.35688784,  87661.7420679 , 139710.13993728,\n",
       "       129259.52703598, 304627.07761748, 246268.60270855, 121726.01528584,\n",
       "       203729.74823715, 109013.52511517, 201848.20220928, 104277.98985744,\n",
       "       301113.52350011, 180940.12118383, 205315.7917073 , 108549.26962867,\n",
       "       297441.80012707, 191446.29075154,  80877.20936534, 119468.08722598,\n",
       "       136645.14076284, 172547.45810224,  93622.34758556, 174579.50850439,\n",
       "       176130.42311227, 151286.46453773, 184918.52363906, 118926.11115964,\n",
       "       180082.43834398, 235247.84168343, 126261.7848023 , 136542.93918452,\n",
       "       174870.60461413, 200442.86782485, 142816.5508268 , 211278.30512939,\n",
       "       238311.35465553, 104007.56949109, 124532.61191864, 175380.33790431,\n",
       "       103909.25793667, 199635.29103885, 137982.12911013, 182151.21430782,\n",
       "       191960.7087508 , 170109.52535472, 307652.24873536,  59788.23777761,\n",
       "       233239.5878008 , 144246.29842904, 119092.08360476,  85100.68137195,\n",
       "       193049.72611109, 147284.2314044 , 148992.86678814, 219356.72123999,\n",
       "       160047.55864693,  90834.75784941, 123627.70779384, 135933.03917473,\n",
       "       140868.70231334, 188370.56567114, 162744.68702682, 107196.15529256,\n",
       "       172875.3860183 ,  80157.89811188,  75292.80002959, 217856.76170494,\n",
       "       191182.94803157, 135497.56018013, 133286.30138477, 179715.76422262,\n",
       "       230920.42498791, 367676.06335648, 376017.10845769, 115574.80939597,\n",
       "       227214.2255511 , 129094.23737412, 230182.08644535, 346628.39733694,\n",
       "       297632.9558705 , 186199.63693124, 226180.27558058, 141464.36481721,\n",
       "       113182.99476627,  86493.76998782, 219028.10906246, 340683.34695502,\n",
       "       182182.3038461 , 106739.4855516 , 216779.566242  , 258517.28629822,\n",
       "       124885.90864027])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(val_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3327144-61e7-4e82-9bd2-03c823d6d9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bf331cf-5f1d-4f3c-8836-4e2c32542557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502694034.3952281"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse=mean_squared_error(train_targets,y_pred)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4942101e-b393-4be0-b194-3d5be4734ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "337705fd-15ba-406e-a263-20c9b328f380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158500. 410000. 110500. 133000. 285000.  81000. 183000. 148500.  81000.\n",
      " 167500. 189950. 123000.  90000. 164990. 172400. 109000. 215000. 139400.\n",
      " 108000. 214000. 115000. 235128. 174000. 110000. 230000. 181000. 227680.\n",
      " 108000. 178000. 176000. 112500. 233000. 169000.  97000. 250000. 129500.\n",
      " 115000. 213000. 290000. 115000. 112500. 268000. 103600. 440000. 156000.\n",
      " 139000. 100000. 125500. 466500. 139000. 103600. 170000. 110000. 424870.\n",
      " 140000. 187500. 188500. 142000. 132000. 124000.  79900. 177000. 325300.\n",
      " 325000. 249700. 230000. 110000. 325624. 123600. 155000. 118964. 124000.\n",
      "  97000. 102000. 501837. 181000. 290000. 260000. 139000. 126000.  89500.\n",
      "  76000. 143250.  62383. 158000. 135000. 270000. 180500. 148000. 191000.\n",
      " 145000. 165150. 138500. 294000.  85000. 186000. 129900. 148800. 279500.\n",
      " 200000. 175000. 208500. 375000. 116900. 175000. 186500. 155000. 280000.\n",
      " 169900. 211000.  55000. 123600. 154000. 135000. 226000. 105000. 120500.\n",
      " 111000. 158000. 280000. 184000. 143000. 172400. 185000. 175000. 144000.\n",
      " 263000. 119500. 129500. 190000. 184000. 410000. 176000. 143000.  80000.\n",
      " 326000. 370878. 144000. 232000. 625000. 440000. 144000. 178000. 145000.\n",
      " 134000. 138500. 207500. 198900. 104900.  55000. 115000. 125000. 237500.\n",
      " 145000.  85000. 124000. 131500. 150000.  82500. 145000. 212000. 155000.\n",
      " 372402.  95000. 142000.  85000. 155000. 340000. 446261. 159500. 402861.\n",
      "  85500. 135000. 176000. 410000. 143000. 139000. 231500. 119900. 177000.\n",
      " 150750.  73000. 124000. 167500. 237000. 143000. 274000. 154000. 202665.\n",
      " 102000. 125000. 128000. 127500. 129500. 185000. 179500. 187500.  55000.\n",
      " 189000. 105000. 201800. 190000. 180000. 410000. 185500. 129500. 237000.\n",
      " 160000. 145000. 100000. 235000. 137500.  82500. 148500. 260000. 372402.\n",
      " 175500. 129000.  85000. 110000. 122000. 215000. 197900. 110000. 212000.\n",
      " 163000.  82000. 115000. 133000. 108000. 113000. 183200. 108000. 168500.\n",
      " 230500. 169000. 194000. 131500. 159500. 113000. 116000. 263000. 236000.\n",
      " 342643. 211000. 119000. 180500. 173000. 142500. 126000. 143900. 163900.\n",
      " 139000.  90350. 129500. 128000. 119900.  89500. 183200. 237000. 440000.\n",
      " 162500. 106500. 215000. 216837. 181000. 165000. 140000. 132250. 163900.\n",
      " 385000. 209500. 226700. 101000. 102000. 156000. 130000. 402861. 130500.\n",
      " 139000. 195000.  84500. 186500.  76000. 394617. 167000. 223500. 120500.\n",
      " 221000. 154000. 143900.  97000. 168500. 168000.  93000. 133000. 162900.\n",
      " 129900. 174000. 106500. 180000. 230500. 115000. 153500. 152000. 197900.\n",
      " 152000. 177000. 186500. 115000. 161750. 197900. 105000. 206900. 162900.\n",
      " 168000. 185000. 171900. 302000. 129000. 279500. 139000. 130000. 127500.\n",
      " 188000. 179200. 131000. 176000. 168000.  90000. 181500. 157500. 126000.\n",
      " 234000. 171900. 155000. 112500. 122500.  81000. 241000. 186500. 130000.\n",
      " 112000. 186500. 154000. 335000. 315000. 134900. 240000.  86000. 466500.\n",
      " 386250. 235000. 158000. 249700. 135000. 144000.  79900. 237000. 301500.\n",
      " 181000. 108000. 258000. 231500. 136500.]\n",
      "1420835943.2684932\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Identify input and target columns\n",
    "\n",
    "input_cols=list(price_df.columns)[1:-1]\n",
    "target_cols=list(train_df.columns)[-1]\n",
    "inputs_df=price_df[input_cols].copy()\n",
    "target_df=train_df[target_cols].copy()\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "\n",
    "numeric_cols=inputs_df.select_dtypes(include=['int64','float64']).columns.to_list()\n",
    "categorical_cols=inputs_df.select_dtypes(include=['object']).columns.to_list()\n",
    "\n",
    "\n",
    "# Impute and scale numeric columns\n",
    "imputer = SimpleImputer().fit(inputs_df[numeric_cols])\n",
    "inputs_df[numeric_cols] = imputer.transform(inputs_df[numeric_cols])\n",
    "scaler = MinMaxScaler().fit(inputs_df[numeric_cols])\n",
    "inputs_df[numeric_cols] = scaler.transform(inputs_df[numeric_cols])\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').fit(inputs_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "inputs_df[encoded_cols]=encoder.transform(inputs_df[categorical_cols])\n",
    "\n",
    "# Create training and validation sets\n",
    "\n",
    "train_inputs,val_inputs,train_targets,val_targets=train_test_split(inputs_df[numeric_cols+encoded_cols],target_df,test_size=0.25,random_state=42)\n",
    "#training decision tree\n",
    "model1=DecisionTreeRegressor(random_state=42)\n",
    "model1.fit(train_inputs,train_targets)\n",
    "train_pred=model1.predict(val_inputs)\n",
    "train_pred\n",
    "mse_rf=mean_squared_error(train_pred,val_targets)\n",
    "print(train_pred)\n",
    "print(mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "983b45a3-9aa1-403c-a602-6ef3f9d07c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numeric_cols] = imputer.transform(test_df[numeric_cols])\n",
    "test_df[numeric_cols] = scaler.transform(test_df[numeric_cols])\n",
    "test_df[encoded_cols] = encoder.transform(test_df[categorical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85445d64-c632-4715-aed0-e4e4e7f0d178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>...</th>\n",
       "      <th>MiscFeature_nan</th>\n",
       "      <th>SaleType_COD</th>\n",
       "      <th>SaleType_CWD</th>\n",
       "      <th>SaleType_Con</th>\n",
       "      <th>SaleType_ConLD</th>\n",
       "      <th>SaleType_ConLI</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.048246</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>0.097693</td>\n",
       "      <td>0.115582</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.205479</td>\n",
       "      <td>0.060609</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.623188</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.06750</td>\n",
       "      <td>0.163536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181507</td>\n",
       "      <td>0.058566</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.905797</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.140149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058647</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195205</td>\n",
       "      <td>0.040562</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>0.106662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138699</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.075342</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.046598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.435360</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.233733</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125856</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.476027</td>\n",
       "      <td>0.087406</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.140411</td>\n",
       "      <td>0.042726</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.059709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.246147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.181507</td>\n",
       "      <td>0.038921</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.05875</td>\n",
       "      <td>0.134302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage   LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0        0.202055  0.048246     0.444444        0.625   0.644928   \n",
       "1        0.205479  0.060609     0.555556        0.625   0.623188   \n",
       "2        0.181507  0.058566     0.444444        0.500   0.905797   \n",
       "3        0.195205  0.040562     0.555556        0.625   0.913043   \n",
       "4        0.075342  0.017318     0.777778        0.500   0.869565   \n",
       "...           ...       ...          ...          ...        ...   \n",
       "1454     0.000000  0.002973     0.333333        0.750   0.710145   \n",
       "1455     0.000000  0.002776     0.333333        0.500   0.710145   \n",
       "1456     0.476027  0.087406     0.444444        0.750   0.637681   \n",
       "1457     0.140411  0.042726     0.444444        0.500   0.869565   \n",
       "1458     0.181507  0.038921     0.666667        0.500   0.876812   \n",
       "\n",
       "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  ...  \\\n",
       "0         0.183333     0.00000    0.082920    0.097693   0.115582  ...   \n",
       "1         0.133333     0.06750    0.163536    0.000000   0.173801  ...   \n",
       "2         0.800000     0.00000    0.140149    0.000000   0.058647  ...   \n",
       "3         0.800000     0.01250    0.106662    0.000000   0.138699  ...   \n",
       "4         0.700000     0.00000    0.046598    0.000000   0.435360  ...   \n",
       "...            ...         ...         ...         ...        ...  ...   \n",
       "1454      0.333333     0.00000    0.000000    0.000000   0.233733  ...   \n",
       "1455      0.333333     0.00000    0.044649    0.000000   0.125856  ...   \n",
       "1456      0.766667     0.00000    0.216867    0.000000   0.000000  ...   \n",
       "1457      0.700000     0.00000    0.059709    0.000000   0.246147  ...   \n",
       "1458      0.733333     0.05875    0.134302    0.000000   0.101884  ...   \n",
       "\n",
       "      MiscFeature_nan  SaleType_COD  SaleType_CWD  SaleType_Con  \\\n",
       "0                 1.0           0.0           0.0           0.0   \n",
       "1                 0.0           0.0           0.0           0.0   \n",
       "2                 1.0           0.0           0.0           0.0   \n",
       "3                 1.0           0.0           0.0           0.0   \n",
       "4                 1.0           0.0           0.0           0.0   \n",
       "...               ...           ...           ...           ...   \n",
       "1454              1.0           0.0           0.0           0.0   \n",
       "1455              1.0           0.0           0.0           0.0   \n",
       "1456              1.0           0.0           0.0           0.0   \n",
       "1457              0.0           0.0           0.0           0.0   \n",
       "1458              1.0           0.0           0.0           0.0   \n",
       "\n",
       "      SaleType_ConLD  SaleType_ConLI  SaleType_ConLw  SaleType_New  \\\n",
       "0                0.0             0.0             0.0           0.0   \n",
       "1                0.0             0.0             0.0           0.0   \n",
       "2                0.0             0.0             0.0           0.0   \n",
       "3                0.0             0.0             0.0           0.0   \n",
       "4                0.0             0.0             0.0           0.0   \n",
       "...              ...             ...             ...           ...   \n",
       "1454             0.0             0.0             0.0           0.0   \n",
       "1455             0.0             0.0             0.0           0.0   \n",
       "1456             0.0             0.0             0.0           0.0   \n",
       "1457             0.0             0.0             0.0           0.0   \n",
       "1458             0.0             0.0             0.0           0.0   \n",
       "\n",
       "      SaleType_Oth  SaleType_WD  \n",
       "0              0.0          1.0  \n",
       "1              0.0          1.0  \n",
       "2              0.0          1.0  \n",
       "3              0.0          1.0  \n",
       "4              0.0          1.0  \n",
       "...            ...          ...  \n",
       "1454           0.0          1.0  \n",
       "1455           0.0          1.0  \n",
       "1456           0.0          1.0  \n",
       "1457           0.0          1.0  \n",
       "1458           0.0          1.0  \n",
       "\n",
       "[1459 rows x 292 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = test_df[numeric_cols + encoded_cols]\n",
    "test_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "336f23bc-dd91-4c03-a557-d94c35858057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[117500. 150000. 231500. ... 153000. 100000. 252678.]\n"
     ]
    }
   ],
   "source": [
    "model1=DecisionTreeRegressor(random_state=42)\n",
    "model1.fit(train_inputs,train_targets)\n",
    "train_pred=model1.predict(test_inputs)\n",
    "train_pred\n",
    "##mse_rf=mean_squared_error(train_pred,val_targets)\n",
    "print(train_pred)\n",
    "##print(mse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3cc7d936-0d25-4a95-a697-30a676153523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133500.  148005.5 185150.  ... 172165.  130037.5 214900. ]\n"
     ]
    }
   ],
   "source": [
    "model2=RandomForestRegressor(random_state=42,n_estimators=10,max_depth=20,max_features=0.25,)\n",
    "model2.fit(train_inputs,train_targets)\n",
    "trainDT_pred=model2.predict(test_inputs)\n",
    "##mse_DT=mean_squared_error(trainDT_pred,val_targets)\n",
    "print(trainDT_pred)\n",
    "##print(mse_DT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e72df0d-60ac-41ca-a295-d44dc35c94c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126475.139278  , 157110.10476188, 179691.7017394 , ...,\n",
       "       142709.57487986, 135180.04832572, 179066.4383267 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3=SVR(kernel='linear',C=100,degree=3,epsilon=0.1)\n",
    "model3.fit(val_inputs,val_targets)\n",
    "trainSV=model3.predict(test_inputs)\n",
    "#mse_svm=mean_squared_error(trainSV,train_targets)\n",
    "trainSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfe9e8fa-ac52-4675-8e19-799f97c8a554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>169277.052498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>187758.393989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>183583.683570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>179317.477511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>150730.079977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>167081.220949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>164788.778231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>219222.423400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>184924.279659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>187741.866657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  169277.052498\n",
       "1     1462  187758.393989\n",
       "2     1463  183583.683570\n",
       "3     1464  179317.477511\n",
       "4     1465  150730.079977\n",
       "...    ...            ...\n",
       "1454  2915  167081.220949\n",
       "1455  2916  164788.778231\n",
       "1456  2917  219222.423400\n",
       "1457  2918  184924.279659\n",
       "1458  2919  187741.866657\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df=pd.read_csv('sample_submission.csv')\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb45731e-a8ac-4080-83ce-febd94d51298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>126475.139278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>157110.104762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>179691.701739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>198002.535339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>178924.664803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>2915</td>\n",
       "      <td>116320.972638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>2916</td>\n",
       "      <td>121761.830381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>2917</td>\n",
       "      <td>142709.574880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>2918</td>\n",
       "      <td>135180.048326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>2919</td>\n",
       "      <td>179066.438327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id      SalePrice\n",
       "0     1461  126475.139278\n",
       "1     1462  157110.104762\n",
       "2     1463  179691.701739\n",
       "3     1464  198002.535339\n",
       "4     1465  178924.664803\n",
       "...    ...            ...\n",
       "1454  2915  116320.972638\n",
       "1455  2916  121761.830381\n",
       "1456  2917  142709.574880\n",
       "1457  2918  135180.048326\n",
       "1458  2919  179066.438327\n",
       "\n",
       "[1459 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df['SalePrice']=trainSV\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a97e0ee-8132-46a9-8ab2-af5cf427501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e274fc-ac31-4f9c-b490-ad06a63a43f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
